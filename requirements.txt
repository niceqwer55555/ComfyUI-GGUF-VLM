llama-cpp-python>=0.3.16
Pillow>=11.0.0
numpy>=1.26.4
requests>=2.32.5
transformers>=4.57.1
accelerate>=1.11.0
pyyaml>=6.0.2
huggingface-hub>=0.34.4